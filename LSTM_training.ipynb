{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "link = \"https://s3-us-west-1.amazonaws.com/helen.assignment/sentiment_master.csv\"\n",
    "df = pd.read_csv(link, names=[\"comments\", \"sentiment\", \"magnitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['magnitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = pd.to_numeric(df['sentiment'],errors='coerce')\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# df.drop(index='NaN', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>comments</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Hi\\nThis backpack which is Show in“read the St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>I place an order and looking forward to using ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Waiting for an year for such an amazing produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Ordered! The science of effectively having an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218313.0</th>\n",
       "      <td>Dear Joao and all the Backers!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218314.0</th>\n",
       "      <td>I will ship all the Kal pieces on this Friday....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218315.0</th>\n",
       "      <td>Can you post an update? And give me some feedb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218316.0</th>\n",
       "      <td>Thanks Andrew for everything! You will have a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218317.0</th>\n",
       "      <td>Congratulations. I can't wait to see it on my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comments  sentiment\n",
       "NaN                                                comments          0\n",
       "0.0       Hi\\nThis backpack which is Show in“read the St...          1\n",
       "1.0       I place an order and looking forward to using ...          1\n",
       "2.0       Waiting for an year for such an amazing produc...          1\n",
       "3.0       Ordered! The science of effectively having an ...          1\n",
       "...                                                     ...        ...\n",
       "218313.0                     Dear Joao and all the Backers!          0\n",
       "218314.0  I will ship all the Kal pieces on this Friday....          1\n",
       "218315.0  Can you post an update? And give me some feedb...          0\n",
       "218316.0  Thanks Andrew for everything! You will have a ...          1\n",
       "218317.0  Congratulations. I can't wait to see it on my ...          1\n",
       "\n",
       "[218319 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['comments'].values[:80000]\n",
    "y = df['sentiment'].values[:80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@Avinash Magdum: \\nok，We have added.',\n",
       "       'To set the IP address manually, click advanced on the first page (the one that you select the Wi-Fi networks). All of the IP address fields are there.  ',\n",
       "       'Order ID\\n278\\nstill waiting', ...,\n",
       "       'Looking great guys!!  Keep up the good work.',\n",
       "       'Dave. When will you shipping?',\n",
       "       '... Not too far from where I live.'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words = number of keywords \n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(x)\n",
    "xtrain= tokenizer.texts_to_sequences(x_train)\n",
    "xtest= tokenizer.texts_to_sequences(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxlen = maximum length per comment to look at\n",
    "maxlen=20\n",
    "xtrain=pad_sequences(xtrain,padding='post', maxlen=maxlen)\n",
    "xtest=pad_sequences(xtest,padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0, ...,  0,  0,  0],\n",
       "       [ 2,  1, 15, ...,  0,  0,  0],\n",
       "       [60, 55,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [72, 68,  1, ...,  0,  0,  0],\n",
       "       [40, 21,  6, ...,  0,  0,  0],\n",
       "       [22, 41,  3, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will there be programs and apps available to make uploading data easy?\n",
      "[21 52 18  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[4])\n",
    "print(xtrain[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52576"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(tokenizer.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 50)            2628800   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                2440      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,651,537\n",
      "Trainable params: 2,651,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=50\n",
    "model=Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size,\n",
    "         output_dim=embedding_dim,\n",
    "         input_length=maxlen))\n",
    "model.add(layers.LSTM(units=50,return_sequences=True))\n",
    "model.add(layers.LSTM(units=10))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
    "     metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples\n",
      "Epoch 1/20\n",
      "72000/72000 [==============================] - 351s 5ms/sample - loss: 0.5529 - accuracy: 0.7141\n",
      "Epoch 2/20\n",
      "72000/72000 [==============================] - 356s 5ms/sample - loss: 0.5344 - accuracy: 0.7276\n",
      "Epoch 3/20\n",
      "72000/72000 [==============================] - 373s 5ms/sample - loss: 0.5293 - accuracy: 0.7316\n",
      "Epoch 4/20\n",
      "72000/72000 [==============================] - 342s 5ms/sample - loss: 0.5256 - accuracy: 0.7347\n",
      "Epoch 5/20\n",
      "72000/72000 [==============================] - 472s 7ms/sample - loss: 0.5212 - accuracy: 0.7350\n",
      "Epoch 6/20\n",
      "72000/72000 [==============================] - 424s 6ms/sample - loss: 0.5187 - accuracy: 0.7397\n",
      "Epoch 7/20\n",
      "72000/72000 [==============================] - 381s 5ms/sample - loss: 0.5144 - accuracy: 0.7425\n",
      "Epoch 8/20\n",
      "72000/72000 [==============================] - 378s 5ms/sample - loss: 0.5100 - accuracy: 0.7449\n",
      "Epoch 9/20\n",
      "72000/72000 [==============================] - 418s 6ms/sample - loss: 0.5057 - accuracy: 0.7502\n",
      "Epoch 10/20\n",
      "72000/72000 [==============================] - 432s 6ms/sample - loss: 0.5016 - accuracy: 0.7520\n",
      "Epoch 11/20\n",
      "72000/72000 [==============================] - 439s 6ms/sample - loss: 0.4972 - accuracy: 0.7561\n",
      "Epoch 12/20\n",
      "72000/72000 [==============================] - 425s 6ms/sample - loss: 0.4914 - accuracy: 0.7596\n",
      "Epoch 13/20\n",
      "72000/72000 [==============================] - 460s 6ms/sample - loss: 0.4852 - accuracy: 0.7644\n",
      "Epoch 14/20\n",
      "72000/72000 [==============================] - 462s 6ms/sample - loss: 0.4804 - accuracy: 0.7672\n",
      "Epoch 15/20\n",
      "72000/72000 [==============================] - 445s 6ms/sample - loss: 0.4724 - accuracy: 0.7711\n",
      "Epoch 16/20\n",
      "72000/72000 [==============================] - 429s 6ms/sample - loss: 0.4677 - accuracy: 0.7754\n",
      "Epoch 17/20\n",
      "72000/72000 [==============================] - 431s 6ms/sample - loss: 0.4597 - accuracy: 0.7799\n",
      "Epoch 18/20\n",
      "72000/72000 [==============================] - 427s 6ms/sample - loss: 0.4539 - accuracy: 0.7842\n",
      "Epoch 19/20\n",
      "72000/72000 [==============================] - 431s 6ms/sample - loss: 0.4473 - accuracy: 0.7881\n",
      "Epoch 20/20\n",
      "72000/72000 [==============================] - 433s 6ms/sample - loss: 0.4408 - accuracy: 0.7909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92ddef2690>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,y_train, epochs=20, batch_size=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_half_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_half_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = keras.models.load_model('my_half_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000/72000 [==============================] - 36s 502us/sample - loss: 0.4130 - accuracy: 0.8021\n",
      "Training Accuracy:  0.8\n",
      "8000/8000 [==============================] - 3s 329us/sample - loss: 0.5338 - accuracy: 0.7369\n",
      "Test Accuracy:  0.74\n"
     ]
    }
   ],
   "source": [
    "loss, acc = my_model.evaluate(xtrain, y_train, verbose=True)\n",
    "print(\"Training Accuracy: \", acc.round(2))\n",
    "\n",
    " \n",
    "loss, acc = my_model.evaluate(xtest, y_test, verbose=True)\n",
    "print(\"Test Accuracy: \", acc.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=my_model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"To be honest, I don't have a problem with the water flow. I don't chug my water so I don't suck more than I need to. I think you all are over reacting because you have waited a while so you are expecting an absolutely perfect product because of the wait. I don't have any problems with it and love it in every way.\", 1, 0.00235788)\n"
     ]
    }
   ],
   "source": [
    "result=zip(x_test[:10], y_test[:10], ypred[10])\n",
    "for i in result:\n",
    " print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45604467],\n",
       "       [0.11726645],\n",
       "       [0.7339141 ],\n",
       "       ...,\n",
       "       [0.53813964],\n",
       "       [0.00257869],\n",
       "       [0.5505388 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
